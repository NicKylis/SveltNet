{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/NicKylis/letter_recognition/blob/layman/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kI0kvbgla13L",
    "outputId": "b6d045cc-a3a5-447e-c86b-4b593a6bddb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import kagglehub\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Conv2D, ReLU, MaxPooling2D, UpSampling2D, Dropout, BatchNormalization, Flatten, Dense\n",
    "from cv2 import cv2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "print (\"hello world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "iya-qDQePUK9"
   },
   "outputs": [],
   "source": [
    "# def clean_image(img): Unused, increased losses in data\n",
    "#     kernel = np.ones((3, 3), np.uint8)\n",
    "#     img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "#     img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "#     return img\n",
    "def get_MNIST_dataset(train_generator, batch_size=32, val_split=0.2, random_state=42):\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "    x_train = x_train.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0 #Normalize data\n",
    "    x_test = x_test.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
    "    #Split data to train and valitation\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = val_split, random_state=random_state)\n",
    "\n",
    "    num_classes = 10  # MNIST has 10 classes (digits 0-9)\n",
    "    y_train = to_categorical(y_train, num_classes)\n",
    "    y_val = to_categorical(y_val, num_classes)\n",
    "    y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "    #Use default ImageDataGenerator for inmutable images\n",
    "    val_test_generator = ImageDataGenerator()\n",
    "    train_gen = train_generator.flow(x_train, y_train, batch_size=batch_size)\n",
    "    val_gen = val_test_generator.flow(x_val, y_val, batch_size=batch_size)\n",
    "    test_gen = val_test_generator.flow(x_test, y_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_gen, val_gen, test_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "pezpnYEJ4wdw"
   },
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator()\n",
    "train_generator_aug = ImageDataGenerator(#Use this one, higher accuracy percentage\n",
    "    rotation_range=25,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,)\n",
    "\n",
    "train_data, val_data, test_data = get_MNIST_dataset(train_generator, batch_size=32, val_split=0.2, random_state=42)\n",
    "train_data_aug, val_data_aug, test_data_aug = get_MNIST_dataset(train_generator, batch_size=32, val_split=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_36 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization_36 (Bat  (None, 26, 26, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_36 (ReLU)             (None, 26, 26, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPoolin  (None, 13, 13, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 13, 13, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPoolin  (None, 6, 6, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " up_sampling2d_20 (UpSamplin  (None, 12, 12, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 10, 10, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_37 (Bat  (None, 10, 10, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_37 (ReLU)             (None, 10, 10, 64)        0         \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 10, 10, 64)        0         \n",
      "                                                                 \n",
      " up_sampling2d_21 (UpSamplin  (None, 20, 20, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 10, 10, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_38 (Bat  (None, 8, 8, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_38 (ReLU)             (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 6, 6, 32)          18464     \n",
      "                                                                 \n",
      " batch_normalization_39 (Bat  (None, 6, 6, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_39 (ReLU)             (None, 6, 6, 32)          0         \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 1152)              0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 100)               115300    \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 191,286\n",
      "Trainable params: 190,902\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Conv2D(32, (3, 3), strides=(1, 1), activation=None, input_shape=(28, 28, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.2)) #Original image feature extraction\n",
    "\n",
    "#Feature extraction from simulating Opening operation on image\n",
    "model.add(MaxPooling2D((2, 2)))#Erosion\n",
    "model.add(UpSampling2D(size=(2, 2)))#Dilation\n",
    "model.add(Conv2D(64, (3, 3), activation=None))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(Dropout(0.25))#0.15\n",
    "\n",
    "#Feature extraction from simulating Closing operation on image\n",
    "model.add(UpSampling2D(size=(2, 2)))#Dilation\n",
    "model.add(MaxPooling2D(2, 2))#Erosion\n",
    "model.add(Conv2D(64, (3, 3), activation=None))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation=None))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10, activation='softmax'))          \n",
    "\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "loss_fn = CategoricalCrossentropy(label_smoothing=0.1)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "#Can use more epochs, should improve performance marginally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kdyzQArVQNUB",
    "outputId": "0245b508-2593-4ed2-d3af-81fd045577c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.6923 - accuracy: 0.9504 - val_loss: 0.5867 - val_accuracy: 0.9768 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5990 - accuracy: 0.9819 - val_loss: 0.5639 - val_accuracy: 0.9872 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5837 - accuracy: 0.9856 - val_loss: 0.5512 - val_accuracy: 0.9876 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5742 - accuracy: 0.9877 - val_loss: 0.5488 - val_accuracy: 0.9892 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5665 - accuracy: 0.9898 - val_loss: 0.5378 - val_accuracy: 0.9905 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5637 - accuracy: 0.9903 - val_loss: 0.5404 - val_accuracy: 0.9898 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5596 - accuracy: 0.9912 - val_loss: 0.5376 - val_accuracy: 0.9908 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5555 - accuracy: 0.9928 - val_loss: 0.5395 - val_accuracy: 0.9907 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5530 - accuracy: 0.9931 - val_loss: 0.5348 - val_accuracy: 0.9923 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5511 - accuracy: 0.9936 - val_loss: 0.5354 - val_accuracy: 0.9898 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5496 - accuracy: 0.9938 - val_loss: 0.5328 - val_accuracy: 0.9924 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5476 - accuracy: 0.9946 - val_loss: 0.5322 - val_accuracy: 0.9902 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5465 - accuracy: 0.9948 - val_loss: 0.5307 - val_accuracy: 0.9923 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5460 - accuracy: 0.9948 - val_loss: 0.5338 - val_accuracy: 0.9916 - lr: 0.0010\n",
      "Epoch 15/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5443 - accuracy: 0.9952 - val_loss: 0.5308 - val_accuracy: 0.9917 - lr: 0.0010\n",
      "Epoch 16/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5433 - accuracy: 0.9956 - val_loss: 0.5310 - val_accuracy: 0.9925 - lr: 0.0010\n",
      "Epoch 17/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5382 - accuracy: 0.9967 - val_loss: 0.5249 - val_accuracy: 0.9937 - lr: 5.0000e-04\n",
      "Epoch 18/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5371 - accuracy: 0.9971 - val_loss: 0.5247 - val_accuracy: 0.9940 - lr: 5.0000e-04\n",
      "Epoch 19/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5359 - accuracy: 0.9969 - val_loss: 0.5229 - val_accuracy: 0.9941 - lr: 5.0000e-04\n",
      "Epoch 20/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5357 - accuracy: 0.9974 - val_loss: 0.5239 - val_accuracy: 0.9941 - lr: 5.0000e-04\n",
      "Epoch 21/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5359 - accuracy: 0.9972 - val_loss: 0.5238 - val_accuracy: 0.9942 - lr: 5.0000e-04\n",
      "Epoch 22/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5357 - accuracy: 0.9973 - val_loss: 0.5238 - val_accuracy: 0.9935 - lr: 5.0000e-04\n",
      "Epoch 23/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5328 - accuracy: 0.9980 - val_loss: 0.5220 - val_accuracy: 0.9946 - lr: 2.5000e-04\n",
      "Epoch 24/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5326 - accuracy: 0.9981 - val_loss: 0.5212 - val_accuracy: 0.9946 - lr: 2.5000e-04\n",
      "Epoch 25/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5325 - accuracy: 0.9979 - val_loss: 0.5232 - val_accuracy: 0.9943 - lr: 2.5000e-04\n",
      "Epoch 26/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5316 - accuracy: 0.9983 - val_loss: 0.5214 - val_accuracy: 0.9947 - lr: 2.5000e-04\n",
      "Epoch 27/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5318 - accuracy: 0.9984 - val_loss: 0.5203 - val_accuracy: 0.9946 - lr: 2.5000e-04\n",
      "Epoch 28/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5319 - accuracy: 0.9984 - val_loss: 0.5212 - val_accuracy: 0.9943 - lr: 2.5000e-04\n",
      "Epoch 29/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5315 - accuracy: 0.9981 - val_loss: 0.5211 - val_accuracy: 0.9947 - lr: 2.5000e-04\n",
      "Epoch 30/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5311 - accuracy: 0.9983 - val_loss: 0.5217 - val_accuracy: 0.9948 - lr: 2.5000e-04\n",
      "Epoch 31/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5304 - accuracy: 0.9987 - val_loss: 0.5208 - val_accuracy: 0.9948 - lr: 1.2500e-04\n",
      "Epoch 32/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5301 - accuracy: 0.9985 - val_loss: 0.5205 - val_accuracy: 0.9947 - lr: 1.2500e-04\n",
      "Epoch 33/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5300 - accuracy: 0.9989 - val_loss: 0.5212 - val_accuracy: 0.9948 - lr: 1.2500e-04\n",
      "Epoch 34/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5300 - accuracy: 0.9986 - val_loss: 0.5204 - val_accuracy: 0.9949 - lr: 6.2500e-05\n",
      "Epoch 35/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5298 - accuracy: 0.9987 - val_loss: 0.5197 - val_accuracy: 0.9947 - lr: 6.2500e-05\n",
      "Epoch 36/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5297 - accuracy: 0.9989 - val_loss: 0.5200 - val_accuracy: 0.9947 - lr: 6.2500e-05\n",
      "Epoch 37/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5297 - accuracy: 0.9988 - val_loss: 0.5203 - val_accuracy: 0.9947 - lr: 6.2500e-05\n",
      "Epoch 38/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5297 - accuracy: 0.9987 - val_loss: 0.5199 - val_accuracy: 0.9948 - lr: 6.2500e-05\n",
      "Epoch 39/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5294 - accuracy: 0.9987 - val_loss: 0.5198 - val_accuracy: 0.9947 - lr: 3.1250e-05\n",
      "Epoch 40/40\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5290 - accuracy: 0.9990 - val_loss: 0.5201 - val_accuracy: 0.9947 - lr: 3.1250e-05\n"
     ]
    }
   ],
   "source": [
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, min_lr=1e-6)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "history = model.fit(train_data_aug,\n",
    "         validation_data=val_data_aug,\n",
    "         epochs=40,\n",
    "         batch_size=32,\n",
    "         shuffle=True\n",
    "         ,callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XRF7bF5oRyGi",
    "outputId": "82abe401-4735-43f0-b89f-ac7e8a795419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.5178 - accuracy: 0.9952\n",
      "The accuracy of the model is 99.52%\n",
      "The loss of the model is 0.5178\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_data_aug)\n",
    "print(f'The accuracy of the model is {round(acc * 100, 2)}%')\n",
    "print(f'The loss of the model is {round(loss, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('best_weights.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
